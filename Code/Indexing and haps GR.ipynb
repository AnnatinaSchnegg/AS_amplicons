{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import fcsparser\n",
    "\n",
    "#Indexing functions defined here\n",
    "\n",
    "def get_inx(meta : dict):  #extract index data\n",
    "    i = 1\n",
    "    key = f'INDEX SORTING LOCATIONS_{i}'\n",
    "    sort_locs = [] #Sort locations from the metadata, numerical row then column starting at 0\n",
    "    while key in meta:\n",
    "        sort_locs.append(meta[key])\n",
    "        i += 1\n",
    "        key = f'INDEX SORTING LOCATIONS_{i}'\n",
    "    sort_locs = ''.join(sort_locs).split(';')\n",
    "    return sort_locs\n",
    "\n",
    "\n",
    "def count_files(directory): #count files in a directory\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        count += 1\n",
    "        \n",
    "    return count    \n",
    "\n",
    "\n",
    "def plate_qc(directory, data_name): #visual check of which well contain cells\n",
    "    #count the plates\n",
    "    plotlen = int(math.ceil(count_files(directory)/2))  #math.ceil rounds up to account for an odd number of plates\n",
    "\n",
    "    fig, ax = plt.subplots(plotlen, 2, figsize = (16,(plotlen*5)))\n",
    "    ax = ax.ravel()\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace=.3)\n",
    "\n",
    "    xwell = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    ywell = [0,1,2,3,4,5,6,7,8,9,0,11,12,13,14,15]\n",
    "    allwells = []\n",
    "\n",
    "    for a in ywell: #this creates a list of all possible locations\n",
    "        for b in xwell:\n",
    "            allwells.append(str(a) + ','+ str(b))\n",
    "\n",
    "    #Read in files and plot the data for each\n",
    "\n",
    "    for count, filename in enumerate(os.listdir(directory)):\n",
    "        fn = os.path.join(directory, filename)\n",
    "        plateid = (fn.split('/'))[4]\n",
    "\n",
    "        meta, data = fcsparser.parse(fn, reformat_meta=True)\n",
    "        \n",
    "        sort_locs = get_inx(meta)\n",
    "\n",
    "        for well in allwells:\n",
    "            if well in sort_locs:  #if the well is in the list of wells with a sorted cell the colour will be darker\n",
    "                alpha = 0.8\n",
    "            else:\n",
    "                alpha = 0.1        #plot empty wells in a lighter shade\n",
    "\n",
    "            y, x = well.split(',')\n",
    "            ax[count].scatter(x, y, alpha=alpha, color='gray')      \n",
    "        ax[count].set_title(plateid)\n",
    "        ax[count].invert_yaxis()  #flip the axis so the plate order looks natural\n",
    "        ax[count].set_xticklabels(['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24'])\n",
    "        ax[count].set_yticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'])\n",
    "\n",
    "    fig.suptitle(f'{data_name}', fontsize=14)    \n",
    "    fig.savefig(f'../Results/Indexing/{data_name}_plot_by_plate.png',dpi=300)     \n",
    "    \n",
    "    return\n",
    "\n",
    "def get_comp_data(directory, plate_key, channel_key, plot = False): #retrieve and compensate flow data, optional plot of comp matrix\n",
    "\n",
    "    data_dict = {}\n",
    "    data_dict_comp = {}\n",
    "    \n",
    "    #count the plates\n",
    "    plotlen = int(math.ceil(count_files(directory)/2))  #math.ceil rounds up to account for an odd number of plates\n",
    "    \n",
    "    #Set up comp plots\n",
    "    \n",
    "    fig, ax = plt.subplots(plotlen, 2, figsize = (12,(plotlen*4)))\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace=1.5)\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for count, filename in enumerate(os.listdir(directory)):\n",
    "        fn = os.path.join(directory, filename)\n",
    "        plateid = (fn.split('/'))[4]\n",
    "\n",
    "        meta, data = fcsparser.parse(fn, reformat_meta=True)\n",
    "\n",
    "        sort_locs = get_inx(meta)\n",
    "\n",
    "        wells = []\n",
    "        for loc in sort_locs:\n",
    "            if loc == '':\n",
    "                continue\n",
    "            row_index, col = loc.split(',')\n",
    "            col = str(int(col)+1)\n",
    "            row = chr(65 + int(row_index)) \n",
    "            well = row+col\n",
    "            wells.append(well)   #Wells is a list of well locations with data derived from the index file\n",
    "\n",
    "        # Get antibodies and rename with well names\n",
    "        channel_idx = [int(x[2:-1]) for x in meta if x.startswith('$P') and x.endswith('S')]\n",
    "        #channeld = {meta['_channel_names_'][i-1]: meta[f'$P{i}S'] for i in channel_idx} #can automatically retrieve labels, but causes issues if labelling is inconsistent between all plates\n",
    "\n",
    "        data.index = pd.Index(wells, name='Sorted well') #Renames index with well name\n",
    "\n",
    "        # Load compensation\n",
    "        comp_fields = meta['SPILL'].split(',')\n",
    "        n = int(comp_fields[0])\n",
    "        channels = comp_fields[1: n+1]\n",
    "        matrix = np.asarray(comp_fields[n+1:]).astype(np.float64).reshape((n, n)) \n",
    "\n",
    "        matrix = numpy.linalg.inv(matrix)\n",
    "\n",
    "        spill_matrix = pd.DataFrame(\n",
    "            matrix,\n",
    "            index=channels,\n",
    "            columns=channels,\n",
    "        )  #spill_matrix is the comp matrix\n",
    "\n",
    "        #Plots compensation matrix\n",
    "        # Reorder the dyes by wavelength\n",
    "        wls = [int(x.split('/')[0][-3:]) for x in channels]\n",
    "        idx = np.argsort(wls)\n",
    "        spill_by_wls = spill_matrix.iloc[idx].T.iloc[idx].T\n",
    "\n",
    "        sns.heatmap(spill_by_wls, ax=ax[count])\n",
    "        ax[count].set_title(plateid)\n",
    "\n",
    "        #Apply comp and replace column names with antibodies\n",
    "        data_comp = data.copy()\n",
    "        compensation = spill_matrix\n",
    "\n",
    "        for channel in channels:\n",
    "            data_comp[channel] = compensation.loc[:,channel].values @ data[channels].values.T #@ for matrix multiplication\n",
    "\n",
    "        #Store df and compdf for this iteration as a unique variable - \n",
    "        #data_comp.rename(columns = channeld, inplace = True) #Use is automatically assigning channel names\n",
    "        data_comp.rename(columns = channel_key, inplace = True)\n",
    "        plate = plate_key.get(filename) #pull the plate name for this file and use to label output dictionaries\n",
    "        data_comp['Well'] = data_comp.index.get_level_values(0)\n",
    "        data_comp['Plate'] = plate  #add new column with plate name\n",
    "        data_dict_comp[plate] = data_comp #output df into a dictionary\n",
    "\n",
    "    fig.tight_layout()  \n",
    "    \n",
    "    if plot == False:\n",
    "        plt.close() \n",
    "\n",
    "    alldata_comp = pd.concat(data_dict_comp.values(), axis = 0)\n",
    "    alldata_comp['Plate_Well'] = alldata_comp['Plate'].astype(str) + '_' + alldata_comp['Well'].astype(str)\n",
    "    \n",
    "    return alldata_comp\n",
    "\n",
    "\n",
    "def flowplot_byplate(compdata, plot_list, logs, gates,  data_name, plot = True, save = False):\n",
    "    \n",
    "    sourcedata = compdata.copy()\n",
    "    plotlen = int(math.ceil(len(plot_list)/2))\n",
    "    \n",
    "    plates = sourcedata['Plate'].drop_duplicates().to_list()\n",
    "    cols = sns.color_palette('husl', n_colors = len(plates))\n",
    "    palette = dict(zip(plates, cols))\n",
    "\n",
    "    sourcedata['Colour'] = sourcedata['Plate'].map(palette)\n",
    "\n",
    "    fig, axs = plt.subplots(plotlen,2, figsize = (12,(plotlen*4)))\n",
    "    axs = axs.ravel()\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace=1.5)\n",
    "\n",
    "    for ax,y in zip(axs, plot_list):\n",
    "        x_label = y[0]\n",
    "        y_label = y[1]\n",
    "        ax.scatter(sourcedata[x_label] + 11, sourcedata[y_label] + 11, alpha = 0.3, c = sourcedata['Colour'], s = 5)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "       #ax.legend()\n",
    "        if x_label in logs:\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlim(left = 10)\n",
    "        if y_label in logs:\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylim(bottom = 10)\n",
    "        if x_label in gates:\n",
    "            ax.axvline(gates[x_label], ls = '--', c = 'k')\n",
    "        if y_label in gates:\n",
    "            ax.axhline(gates[y_label], ls = '--', c = 'k')   \n",
    "        \n",
    "        for hap in palette:\n",
    "            point = ax.scatter([], [], color=palette[hap], s = 20, alpha = 0.3, label=hap)\n",
    "            ax.add_artist(point)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.,title='Plate')\n",
    "        \n",
    "        ax.autoscale_view()  \n",
    "\n",
    "    fig.suptitle(f'{data_name}', fontsize=16) \n",
    "    \n",
    "    if save == True:\n",
    "        fig.savefig(f'../Results/Indexing/{data_name}_plot_by_plate.png',dpi=300) \n",
    "    \n",
    "    if plot == False:\n",
    "        plt.close()\n",
    "        \n",
    "def flowplot_bycelltype(assigndata, plot_list, logs, gates,  data_name, plot = True, save = False):\n",
    "    \n",
    "    sourcedata = assigndata.copy()\n",
    "    plotlen = int(math.ceil(len(plot_list)/2))\n",
    "    \n",
    "    plates = sourcedata['celltype'].drop_duplicates().to_list()\n",
    "    cols = sns.color_palette('husl', n_colors = len(plates))\n",
    "    palette = dict(zip(plates, cols))\n",
    "\n",
    "    sourcedata['Colour'] = sourcedata['celltype'].map(palette)\n",
    "\n",
    "    fig, axs = plt.subplots(plotlen,2, figsize = (12,(plotlen*4)))\n",
    "    axs = axs.ravel()\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace=1.5)\n",
    "\n",
    "    for ax,y in zip(axs, plot_list):\n",
    "        x_label = y[0]\n",
    "        y_label = y[1]\n",
    "        ax.scatter(sourcedata[x_label] + 11, sourcedata[y_label] + 11, alpha = 0.3, c = sourcedata['Colour'], s = 5)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "       #ax.legend()\n",
    "        if x_label in logs:\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlim(left = 10)\n",
    "        if y_label in logs:\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylim(bottom = 10)\n",
    "        if x_label in gates:\n",
    "            ax.axvline(gates[x_label], ls = '--', c = 'k')\n",
    "        if y_label in gates:\n",
    "            ax.axhline(gates[y_label], ls = '--', c = 'k')   \n",
    "        \n",
    "        for hap in palette:\n",
    "            point = ax.scatter([], [], color=palette[hap], s = 20, alpha = 0.3, label=hap)\n",
    "            ax.add_artist(point)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.,title='Cell type')\n",
    "        \n",
    "        ax.autoscale_view()  \n",
    "\n",
    "    fig.suptitle(f'{data_name}', fontsize=16)   \n",
    "    \n",
    "    if save == True:\n",
    "        fig.savefig(f'../Results/Indexing/{data_name}_plot_by_celltype.png',dpi=300) \n",
    "    \n",
    "    if plot == False:\n",
    "        plt.close()        \n",
    "\n",
    "def MDS_BM_celltype_assign(source, gates, data_name, save = False):\n",
    "#Takes 3 inputs, source df, gates dictionary, string containing name for data output\n",
    "#Assume sort gates actually dumped dead, lin pos cells\n",
    "\n",
    "    data_in = source.copy()\n",
    "\n",
    "    #Create boolean matrix based on gates in new columns\n",
    "\n",
    "    data_in['CD34_pos'] = data_in['CD34-PE'] >= gates['CD34-PE']\n",
    "    data_in['CD38_pos'] = data_in['CD38-APC-cy7'] >= gates['CD38-APC-cy7']\n",
    "    data_in['CD38_neg'] = data_in['CD38-APC-cy7'] < gates['CD38-APC-cy7']\n",
    "    data_in['IL1RAP_pos'] = data_in['IL1RAP-APC'] >= gates['IL1RAP-APC']\n",
    "    data_in['IL1RAP_neg'] = data_in['IL1RAP-APC'] < gates['IL1RAP-APC']\n",
    "    data_in['CD45RA_pos'] = data_in['CD45RA-FITC'] >= gates['CD45RA-FITC']\n",
    "    data_in['CD45RA_neg'] = data_in['CD45RA-FITC'] < gates['CD45RA-FITC']\n",
    "    data_in['CD123_pos'] = data_in['CD123-PE-Cy7'] >= gates['CD123-PE-Cy7']\n",
    "    data_in['CD123_neg'] = data_in['CD123-PE-Cy7'] < gates['CD123-PE-Cy7']\n",
    "    data_in['CD90_pos'] = data_in['CD90-BV421'] >= gates['CD90-BV421']\n",
    "    data_in['CD90_neg'] = data_in['CD90-BV421'] < gates['CD90-BV421']\n",
    "\n",
    "    #Define each cell type - doing this explicitly to make code easier to follow. Tweaked to include IL1RAP neg for normal 38- cells\n",
    "\n",
    "    mds_sc1 = ['CD34_pos','CD38_neg','IL1RAP_pos']\n",
    "    mds_sc2 = ['CD34_pos','CD38_neg','CD45RA_pos']\n",
    "    mds_sc3 = ['CD34_pos','CD38_neg','CD123_pos']\n",
    "    #hsc = ['CD34_pos','CD38_neg','IL1RAP_neg','CD45RA_neg','CD123_neg','CD90_pos'] \n",
    "    #mpp = ['CD34_pos','CD38_neg','IL1RAP_neg','CD45RA_neg','CD123_neg','CD90_neg']\n",
    "    healthy_sc = ['CD34_pos','CD38_neg','IL1RAP_neg','CD45RA_neg','CD123_neg']\n",
    "    cmp = ['CD34_pos','CD38_pos','CD45RA_neg','CD123_pos']\n",
    "    gmp = ['CD34_pos','CD38_pos','CD45RA_pos']\n",
    "    mep = ['CD34_pos','CD38_pos','CD45RA_neg','CD123_neg']\n",
    "\n",
    "    col_names = ['mds_sc1', 'mds_sc2','mds_sc2','healthy_sc', 'cmp', 'gmp','mep']\n",
    "    celltypes = ['MDS_SC', 'MDS_SC','MDS_SC','HEALTHY_SC',  'CMP', 'GMP', 'MEP']\n",
    "    alltypes = [mds_sc1, mds_sc2, mds_sc3, healthy_sc, cmp, gmp, mep]\n",
    "\n",
    "    #Store list of which columns are true for each cell type in a dictionary\n",
    "\n",
    "    criteria = dict(zip(col_names, alltypes))\n",
    "\n",
    "    #Use calculated criteria to add cell type true/false columns\n",
    "\n",
    "    for x in col_names:\n",
    "        data_in[x] = (data_in[criteria[x]] == True).all(axis = 1)\n",
    "\n",
    "    data_in['unassigned'] = (data_in[col_names] == False).all(axis = 1)\n",
    "\n",
    "    #Create a new column that contains the cell type\n",
    "\n",
    "    col_names.append('unassigned')  #account for cells that were not assigned\n",
    "    celltypes.append('unassigned')\n",
    "\n",
    "    for a, b in zip(col_names, celltypes):\n",
    "\n",
    "        data_in.loc[data_in[a] == True, 'celltype'] = b \n",
    "\n",
    "    #Define colour palette here, and make a new column for it\n",
    "\n",
    "    ct = data_in['celltype'].drop_duplicates().to_list()\n",
    "    col = sns.color_palette('husl', n_colors = len(ct))\n",
    "    palette = dict(zip(ct, col))\n",
    "    data_in['Colour'] = data_in['celltype'].map(palette)\n",
    "\n",
    "    #Create a file containing assigned cell type for each well\n",
    "    if save == True:\n",
    "        data_in.to_csv(f'../Data/{data_name}_index_refined.tsv', sep = '\\t')    #Save the big df to a file\n",
    "        #wellID = data_in[['Plate_Well', 'celltype']] #don't need this and it make sthe fucntion fail for bulk cell\n",
    "\n",
    "    #Make a plot of cell type distributions\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    c = data_in['celltype'].value_counts().rename_axis('cell').reset_index(name='counts')\n",
    "    ax = sns.barplot(x='cell', y='counts', data = c, palette = palette)\n",
    "\n",
    "    fig.suptitle(f'{data_name}', fontsize=16)\n",
    "    fig.savefig(f'../Results/Indexing/{data_name}_celltype_dist_refined.png',dpi=300) \n",
    "    \n",
    "    return data_in\n",
    "\n",
    "def PB_celltype_assign(source, gates, data_name, save = False):\n",
    "#Takes 3 inputs, source df, gates dictionary, string containing name for data output\n",
    "#Assume sort gates actually dumped dead, lin pos cells\n",
    "\n",
    "    data_in = source.copy()\n",
    "    \n",
    "    #Create boolean matrix based on gates in new columns\n",
    "    \n",
    "    data_in['CD45_pos'] = data_in['CD45-FITC'] >= gates['CD45-FITC']\n",
    "    data_in['IgD_pos'] = data_in['IgD-BB700'] >= gates['IgD-BB700']\n",
    "    data_in['IgD_neg'] = data_in['IgD-BB700'] < gates['IgD-BB700']\n",
    "    data_in['CD27_pos'] = data_in['Cd27-APC'] >= gates['Cd27-APC']\n",
    "    data_in['CD27_neg'] = data_in['Cd27-APC'] < gates['Cd27-APC']\n",
    "    data_in['CD66b_pos'] = data_in['CD66b-BV421'] >= gates['CD66b-BV421']\n",
    "    data_in['CD66b_neg'] = data_in['CD66b-BV421'] < gates['CD66b-BV421']\n",
    "    data_in['CD16_pos'] = data_in['CD16-PE'] >= gates['CD16-PE']\n",
    "    data_in['CD16_neg'] = data_in['CD16-PE'] < gates['CD16-PE']\n",
    "    data_in['CD14_pos'] = data_in['CD14-Pe-Cy5'] >= gates['CD14-Pe-Cy5']\n",
    "    data_in['CD14_neg'] = data_in['CD14-Pe-Cy5'] < gates['CD14-Pe-Cy5']\n",
    "\n",
    "\n",
    "    #Define each cell type - doing this explicitly to make code easier to follow. Tweaked to include IL1RAP neg for normal 38- cells\n",
    "\n",
    "    nBC = ['CD45_pos','IgD_pos','CD27_neg']\n",
    "    NE = ['CD45_pos','IgD_neg','CD66b_pos','CD16_pos']\n",
    "    Mono = ['CD45_pos','IgD_neg','CD66b_neg']\n",
    "\n",
    "    col_names = ['nBC', 'NE', 'Mono']\n",
    "    celltypes = ['nBC', 'NE', 'Mono']\n",
    "    alltypes = [nBC, NE, Mono]\n",
    "\n",
    "    #Store list of which columns are true for each cell type in a dictionary\n",
    "\n",
    "    criteria = dict(zip(col_names, alltypes))\n",
    "\n",
    "\n",
    "    #Use calculated criteria to add cell type true/false columns\n",
    "\n",
    "    for x in col_names:\n",
    "        data_in[x] = (data_in[criteria[x]] == True).all(axis = 1)\n",
    "\n",
    "    data_in['unassigned'] = (data_in[col_names] == False).all(axis = 1)\n",
    "\n",
    "    #Create a new column that contains the cell type\n",
    "\n",
    "    col_names.append('unassigned')  #account for cells that were not assigned\n",
    "    celltypes.append('unassigned')\n",
    "\n",
    "    for a, b in zip(col_names, celltypes):\n",
    "\n",
    "        data_in.loc[data_in[a] == True, 'celltype'] = b \n",
    "\n",
    "    #Define colour palette here, and make a new column for it\n",
    "\n",
    "    ct = data_in['celltype'].drop_duplicates().to_list()\n",
    "    col = sns.color_palette('husl', n_colors = len(ct))\n",
    "    palette = dict(zip(ct, col))\n",
    "    data_in['Colour'] = data_in['celltype'].map(palette)\n",
    "\n",
    "    #Create a file containing assigned cell type for each well\n",
    "    if save == True:\n",
    "        data_in.to_csv(f'../Data/{data_name}_index.tsv', sep = '\\t')    #Save the big df to a file\n",
    "\n",
    "    #Make a plot of cell type distributions\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    c = data_in['celltype'].value_counts().rename_axis('cell').reset_index(name='counts')\n",
    "    ax = sns.barplot(x='cell', y='counts', data = c, palette = palette)\n",
    "\n",
    "    fig.suptitle(f'{data_name}', fontsize=16)\n",
    "    fig.savefig(f'../Results/Indexing/{data_name}_celltype_dist.png',dpi=300) \n",
    "    \n",
    "    return data_in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haplotype assignment functions now\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import ternary\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "def data_retrieval(sourcefile, pt_initials):\n",
    "    df = pd.read_csv(sourcefile, header = [0,1,2], index_col = 0, sep='\\t')\n",
    "    df = df.stack([0,1,2])\n",
    "    df = df.reorder_levels([1,0,2,3])\n",
    "    df = df.to_frame()  #puts everything back in a dataframe\n",
    "    df.columns = ['Reads']\n",
    "    df['Plate'] = df.index.get_level_values(0)  #These lines send indexes to columns\n",
    "    df['Well'] = df.index.get_level_values(1)\n",
    "    df['Amplicon'] = df.index.get_level_values(2)\n",
    "    df['Genotype'] = df.index.get_level_values(3)\n",
    "    df[['Patient', 'one', 'two']] = df['Amplicon'].str.split('_', expand = True)\n",
    "    df = df.drop(columns = ['one', 'two'])\n",
    "\n",
    "    #Import information about plate cell type and patient\n",
    "    key = pd.read_excel('../Data/Amp_data/Amplicon_metadata_fixed.xlsx', sheet_name = 'PlateID') #should this be an input? also in next fucntion\n",
    "    key = key.drop(['Cell Origin', 'Plate Nr', 'Plate Name','Nr of cells', 'fcs-fle' ], axis=1)\n",
    "    key.rename(columns = {'Comments2':'Plate'}, inplace = True)\n",
    "    key.rename(columns = {'Cell-group':'Celltype'}, inplace = True)\n",
    "    \n",
    "    #Make a dictionary to associate plates with patients and plate with cell type\n",
    "    plate_pt_dict = dict(zip(key.Plate, key.Patient))\n",
    "    plate_cell_dict = dict(zip(key.Plate, key.Celltype))\n",
    "\n",
    "    #Now just look at data from selected patient, and apply filters to identify cells with enough reads/amplicon\n",
    "    #RN_allele_plate is the key dataset going forward\n",
    "    pt_allele_plate = df.loc[df['Patient'].isin([pt_initials])] #Make df with just RN data\n",
    "    pt_allele_plate = pt_allele_plate.drop(columns = 'Patient') #Drop the Patient ID column and other unwanted cols\n",
    "    pt_allele_plate['Cell_type'] = pt_allele_plate['Plate'].replace(plate_cell_dict)\n",
    "    pt_allele_plate['Plate_Well'] = pt_allele_plate['Plate'].astype(str) + '_' + pt_allele_plate['Well'].astype(str)\n",
    "    \n",
    "    return pt_allele_plate\n",
    "\n",
    "def call_haps(data, pt_init, haps, reads,  cutoff):\n",
    "    \n",
    "    cond = f'{pt_init}_{haps}'\n",
    "    print(cond)\n",
    "    \n",
    "    if cond == 'RN_2':\n",
    "        cols = ['RN_RUNX1_c', 'RN_RUNX1_g']\n",
    "        allcols = ['RN_RUNX1_c','RN_RUNX1_g','RN_SRSF2','RN_TET2a','RN_TET2b_c','RN_TET2b_g']\n",
    "    elif cond == 'RN_3':\n",
    "        cols = ['RN_RUNX1_g', 'RN_SRSF2', 'RN_TET2a']\n",
    "        allcols = ['RN_RUNX1_c','RN_RUNX1_g','RN_SRSF2','RN_TET2a','RN_TET2b_c','RN_TET2b_g']\n",
    "    elif cond == 'RN_4':\n",
    "        cols = ['RN_RUNX1_g', 'RN_SRSF2', 'RN_TET2a', 'RN_TET2b_g']\n",
    "        allcols = ['RN_RUNX1_c','RN_RUNX1_g','RN_SRSF2','RN_TET2a','RN_TET2b_c','RN_TET2b_g']\n",
    "    elif cond == 'EL_3':\n",
    "        cols = ['EL_SRSF2', 'EL_TET2a', 'EL_TET2b']\n",
    "        allcols = ['EL_CUX1', 'EL_SRSF2', 'EL_TET2a', 'EL_TET2b', 'EL_TGFB3_c', 'EL_TGFB3_g']\n",
    "    elif cond == 'EL_4':   \n",
    "        cols = ['EL_SRSF2', 'EL_TET2a', 'EL_TET2b',  'EL_TGFB3_g']\n",
    "        allcols = ['EL_CUX1', 'EL_SRSF2', 'EL_TET2a', 'EL_TET2b', 'EL_TGFB3_c', 'EL_TGFB3_g']\n",
    "    elif cond == 'GR_2': \n",
    "        cols = ['GR_TET2a', 'GR_TET2b']\n",
    "        allcols = ['GR_TET2a', 'GR_TET2b']\n",
    "    else:\n",
    "        print('For RN enter 2/3/4 haplotypes, for EL enter 3/4 haplotypes, for GR enter 2 haplotypes')\n",
    "    \n",
    "    #Import information about plate cell type and patient\n",
    "    key = pd.read_excel('../Data/Amp_data/Amplicon_metadata_fixed.xlsx', sheet_name = 'PlateID')\n",
    "    key = key.drop(['Cell Origin', 'Plate Nr', 'Plate Name','Nr of cells', 'fcs-fle' ], axis=1)\n",
    "    key.rename(columns = {'Comments2':'Plate'}, inplace = True)\n",
    "    key.rename(columns = {'Cell-group':'Celltype'}, inplace = True)\n",
    "    \n",
    "    #Make a dictionary to associate plates with patients and plate with cell type\n",
    "    plate_pt_dict = dict(zip(key.Plate, key.Patient))\n",
    "    plate_cell_dict = dict(zip(key.Plate, key.Celltype))\n",
    "    \n",
    "    #Group the data and apply filters\n",
    "    df = data.copy()\n",
    "    df = df.groupby(['Plate', 'Well', 'Amplicon']).sum().unstack()\n",
    "    df.columns = allcols\n",
    "    \n",
    "    df = df.loc[(df[cols] >= reads).all(axis=1)] #df1 contains just the rows with cells we want - use this to create a filter or key\n",
    "    df['Plate'] = df.index.get_level_values(0)  #These lines send indexes to columns\n",
    "    df['Well'] = df.index.get_level_values(1)\n",
    "    df['Plate_Well'] = df['Plate'].astype(str) + '_' + df['Well'].astype(str)\n",
    "    wells = df['Plate_Well'].drop_duplicates().to_list() \n",
    "    print(f'Cells with {reads} reads for {haps} genes = ', len(wells))\n",
    "\n",
    "    df2 = data.copy()\n",
    "    df2 = df2[df2['Plate_Well'].isin(wells)]\n",
    "    df2 = df2[df2['Amplicon'].isin(cols)]\n",
    "    \n",
    "    #Calculate the allele frequency\n",
    "    df2 = df2.iloc[:, 0:1].unstack(level = 3)\n",
    "    df2['Total'] = df2.iloc[: , 0] + df2.iloc[: , 1]\n",
    "    df2['Mut_freq'] = df2.iloc[:, 0]/df2['Total']\n",
    "    \n",
    "    #Assign Wt or MT to each allele\n",
    "    df2 = df2.drop(columns = ['Reads', 'Total'])\n",
    "\n",
    "    conditions = [(df2['Mut_freq'] <= cutoff), (df2['Mut_freq']) > cutoff ]\n",
    "    values = ['w', 'm']\n",
    "    df2['Genotype'] = np.select(conditions, values)\n",
    "    df2 = df2.drop(columns = ['Mut_freq']).unstack(2)\n",
    "    df2.columns = cols\n",
    "    \n",
    "    if 'RN_RUNX1_g' in df2.columns:\n",
    "        df2.loc[:,'RN_RUNX1_g'].replace({'w':'R','m':'r' }, inplace = True)\n",
    "        \n",
    "    if 'RN_SRSF2' in df2.columns:  \n",
    "        df2.loc[:,'RN_SRSF2'].replace({'w':'S','m':'s' }, inplace = True)\n",
    "        \n",
    "    if 'RN_TET2a' in df2.columns:     \n",
    "        df2.loc[:,'RN_TET2a'].replace({'w':'A','m':'a' }, inplace = True)\n",
    "        \n",
    "    if 'RN_TET2b_g' in df2.columns:\n",
    "        df2.loc[:,'RN_TET2b_g'].replace({'w':'B','m':'b' }, inplace = True)\n",
    "        \n",
    "    if 'RN_RUNX1_c' in df2.columns:   \n",
    "        df2.loc[:,'RN_RUNX1_c'].replace({'w':'C','m':'c' }, inplace = True)\n",
    "        \n",
    "    if 'EL_SRSF2' in df2.columns:   \n",
    "        df2.loc[:,'EL_SRSF2'].replace({'w':'S','m':'s' }, inplace = True)\n",
    "        \n",
    "    if 'EL_TET2a' in df2.columns:   \n",
    "        df2.loc[:,'EL_TET2a'].replace({'w':'A','m':'a' }, inplace = True)\n",
    "        \n",
    "    if 'EL_TET2b' in df2.columns:   \n",
    "        df2.loc[:,'EL_TET2b'].replace({'w':'B','m':'b' }, inplace = True)\n",
    "        \n",
    "    if 'EL_TGFB3_g' in df2.columns:   \n",
    "        df2.loc[:,'EL_TGFB3_g'].replace({'w':'T','m':'t' }, inplace = True)\n",
    "        \n",
    "    if 'GR_TET2a' in df2.columns:   \n",
    "        df2.loc[:,'GR_TET2a'].replace({'w':'A','m':'a' }, inplace = True)\n",
    "        \n",
    "    if 'GR_TET2b' in df2.columns:   \n",
    "        df2.loc[:,'GR_TET2b'].replace({'w':'B','m':'b' }, inplace = True)\n",
    "\n",
    "    \n",
    "    df2['Haplotype'] = 'x'\n",
    "\n",
    "    for idx, row in df2.iterrows():\n",
    "        \n",
    "        if cond == 'RN_3':\n",
    "            a = row['RN_SRSF2'] + row['RN_TET2a'] + row['RN_RUNX1_g']\n",
    "        elif cond == 'RN_4':\n",
    "            a = row['RN_SRSF2'] + row['RN_TET2a'] + row['RN_TET2b_g'] + row['RN_RUNX1_g']\n",
    "        elif cond == 'RN_2':\n",
    "            a = row['RN_RUNX1_c'] + row['RN_RUNX1_g']   \n",
    "        elif cond == 'EL_3':\n",
    "            a = row['EL_TET2b'] + row['EL_TET2a'] + row['EL_SRSF2']\n",
    "        elif cond == 'EL_4':\n",
    "            a = row['EL_TET2b'] + row['EL_TET2a'] + row['EL_SRSF2'] + row['EL_TGFB3_g']\n",
    "        elif cond == 'GR_2':\n",
    "            a = row['GR_TET2b'] + row['GR_TET2a']\n",
    "        \n",
    "        row['Haplotype'] = row['Haplotype'].replace('x', a)   \n",
    "\n",
    "    df2['Sort_cell_type'] = df2.index.get_level_values(0)\n",
    "    df2['Sort_cell_type'] = df2['Sort_cell_type'].replace(plate_cell_dict)\n",
    "    df2['Plate'] = df2.index.get_level_values(0)\n",
    "    df2['Well'] = df2.index.get_level_values(1)\n",
    "    df2['Plate_Well'] = df2['Plate'].astype(str) + '_' + df2['Well'].astype(str)\n",
    "    df2 = df2.drop(columns = cols)\n",
    "    df2 = df2.drop(columns = ['Plate', 'Well'])\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def plot_hap_dist_sort_type(data, pt_init): #plot based on cell type (ned to merge output from above)\n",
    "      \n",
    "    #rename the input data and work out how many haplotypes it has\n",
    "    df3 = data.copy()\n",
    "    haps = len(df3.iloc[0,0])\n",
    "    cond = f'{pt_init}_{haps}'\n",
    "    sortcells = df3['Sort_cell_type'].drop_duplicates().to_list()\n",
    "    cellnumb = len(sortcells)\n",
    "    plotlen = int(math.ceil((cellnumb +1)/2))\n",
    "    \n",
    "    #Plot two haplotype data for 3 gene 100 amplicon set - second method to add colour for each haplotype\n",
    "    fig, axes = plt.subplots(plotlen,2, figsize = (16,plotlen*2))\n",
    "    fig.subplots_adjust(hspace = 1.2, wspace=.3)\n",
    "    ax = axes.ravel()\n",
    "    count = 0\n",
    "\n",
    "    c = df3['Haplotype'].value_counts().rename_axis('hap').reset_index(name='counts')\n",
    "\n",
    "    #set up correct variables for the number of input haplotypes\n",
    "    \n",
    "    if cond == 'RN_2':\n",
    "        hap_poss = ['CR', 'Cr', 'cR', 'cr']\n",
    "        \n",
    "    elif cond == 'RN_3':\n",
    "        hap_poss = ['SAB', 'SAb', 'SaB', 'Sab', 'sAB', 'sAb', 'saB', 'sab']\n",
    "\n",
    "    elif cond == 'RN_4':\n",
    "        hap_poss = ['SABR', 'SABr', 'SAbR', 'SAbr', 'SaBR', 'SaBr', 'SabR', 'Sabr', 'sABR', 'sABr', 'sAbR', 'sAbr', 'saBR', 'saBr', 'sabR', 'sabr']\n",
    "      \n",
    "    elif cond == 'GR_2':\n",
    "        hap_poss = ['BA', 'Ba', 'bA', 'ba']\n",
    "\n",
    "    elif cond == 'EL_3':\n",
    "        hap_poss = ['BAS', 'BAs', 'BaS', 'Bas', 'bAS', 'bAs', 'baS', 'bas']\n",
    "\n",
    "    elif cond == 'EL_4':\n",
    "        hap_poss = ['BAST', 'BASt', 'BAsT', 'BAst', 'BaST', 'BaSt', 'BasT', 'Bast', 'bAST', 'bASt', 'bAsT', 'bAst', 'baST', 'baSt', 'basT', 'bast']\n",
    "\n",
    "    num_col = len(hap_poss)\n",
    "    cols = sns.color_palette(\"husl\", num_col)     \n",
    "    color = dict(zip(hap_poss, cols))\n",
    "    hap_order = {}\n",
    "    for i, j in enumerate(hap_poss):\n",
    "        hap_order[1] = j\n",
    "        \n",
    "    #if any haplotype is not present, add it into the frame with freq 0 \n",
    "\n",
    "    for h in hap_poss:\n",
    "        if h not in str(c['hap']):  #for some reason this needs to be called as a string, wasn't needed outside function\n",
    "            dfh = pd.DataFrame([[h, 0]], columns= ['hap', 'counts'])\n",
    "            c = c.append(dfh)\n",
    "            \n",
    "    c['order'] = c['hap']\n",
    "    c = c.replace({'order': hap_order})\n",
    "    c = c.sort_values(by=['order'])\n",
    "    d = c['counts'].sum()\n",
    "    c['proportion'] = c['counts']/d\n",
    "\n",
    "    sns.barplot(x='hap', y='counts', data = c, palette = color, ax = ax[0], ci = None) #fro scatter add  hue = 'hap'\n",
    "    ax[0].set_title('All cells') \n",
    "    ax[0].set_ylabel('Number of cells', fontsize = 11)\n",
    "    ax[0].set_xlabel('Haplotype', fontsize = 11)\n",
    "    ax[0].tick_params(axis='x', labelrotation = 90)\n",
    "\n",
    "    \n",
    "    \n",
    "    for cell in sortcells:\n",
    "        count += 1\n",
    "    \n",
    "        if df3.loc[df3['Sort_cell_type'].isin([cell])].empty == False:\n",
    "\n",
    "            a = df3.loc[df3['Sort_cell_type'].isin([cell])]['Haplotype'].value_counts().rename_axis('hap').reset_index(name='counts')\n",
    "\n",
    "            #if any haplotype is not present, add it into the frame with freq 0 hap_3gene_poss has the possibilities\n",
    "            for h in hap_poss:\n",
    "                if h not in str(a['hap']):  #for some reason this needs to be called as a string, wasn't needed outside function\n",
    "                    dfh = pd.DataFrame([[h, 0]], columns= ['hap', 'counts'])\n",
    "                    a = a.append(dfh)    \n",
    "\n",
    "            a['order'] = a['hap']\n",
    "            a = a.replace({'order': hap_order})\n",
    "            a = a.sort_values(by=['order'])\n",
    "            b = a['counts'].sum()\n",
    "            a['proportion'] = a['counts']/b\n",
    "\n",
    "            sns.barplot(x='hap', y='counts', data = a, palette = color,  ax = ax[count], ci = None) #for scatter add  hue = 'hap'\n",
    "            ax[count].set_title(str(cell)) \n",
    "            ax[count].set_ylabel('Number of cells', fontsize = 11)\n",
    "            ax[count].set_xlabel('Haplotype', fontsize = 11)\n",
    "            ax[count].tick_params(axis='x', labelrotation = 90)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "def plot_index_heatmap(data, title):\n",
    "    df = data.copy()\n",
    "    a = df.groupby(['Haplotype', 'celltype']).size().unstack(fill_value = 0)\n",
    "    alltypes = ['HSC','MPP','HEALTHY_SC','CMP',  'GMP','GMP2', 'MEP', 'MDS_SC',  'NE', 'Mono','nBC', 'unassigned']\n",
    "    col_order = {}            \n",
    "    for i, typ in enumerate(alltypes):\n",
    "         col_order[typ] = i\n",
    "\n",
    "    a = a.T\n",
    "    a['ct'] = a.index.get_level_values(0)\n",
    "    a = a.replace({'ct': col_order})\n",
    "    a = a.sort_values(by=['ct'])\n",
    "    a = a.drop(columns = ['ct'])\n",
    "    a = a.T\n",
    "    b = a.copy()\n",
    "    a = a * 100 /a.sum(axis = 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16, 6))\n",
    "    sns.heatmap(data = a, ax = ax, robust = True)\n",
    "    ax.tick_params(axis='y', labelrotation = 0)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(title)  \n",
    "    \n",
    "    x = df.groupby(['Haplotype', 'celltype']).size().unstack(fill_value = 0)\n",
    "    y = df.groupby(['Haplotype', 'celltype']).size().unstack(fill_value = 0)\n",
    "    x = x.sum(axis = 0)\n",
    "    x = x.to_frame()\n",
    "    x['order'] = x.index.get_level_values(0)\n",
    "    x = x.replace({'order': col_order})\n",
    "    x = x.sort_values(by=['order'])\n",
    "    x = x.drop(columns = ['order'])\n",
    "    x['ct'] = x.index.get_level_values(0)\n",
    "    x.columns = ['number', 'ct']\n",
    "\n",
    "    \n",
    "    fig2, ax2 = plt.subplots(figsize = (12.8, 1))\n",
    "    sns.scatterplot(x = 'ct', y = 'number', data = x, ax = ax2, s = 100, color = 'green')\n",
    "    ax2.tick_params(axis='x', labelrotation = 90)\n",
    "    ax2.set_xlabel('')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.axhline(10, ls = '--', c = 'gray')\n",
    "    ax2.axhline(100, ls = '--', c = 'gray')\n",
    "    ax2.set_ylim(1,1001)\n",
    "    ax2.set_yticks([1,10, 100, 1000])\n",
    "    ax2.set_yticklabels(['1','10', '100','1000]'])    \n",
    "    ax2.set_yscale('log') #use this only with scatterplot\n",
    "    ax2.set_title('Total number of cells for each type')  \n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../Data/GR_BM/Indexed/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-9c03908c0122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Make plate key - note one plate split over 2 index files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../Data/GR_BM/Indexed/'"
     ]
    }
   ],
   "source": [
    "#GR CD34 parameters\n",
    "\n",
    "directory = '../Data/GR_BM/Indexed/'\n",
    "\n",
    "#Make plate key - note one plate split over 2 index files\n",
    "files = []\n",
    "for filename in os.listdir(directory):\n",
    "    files.append(filename)\n",
    "\n",
    "#plates = ['CD34Plate1', 'AS-207','CD34Plate3', 'CD34Plate4', 'AS-208', 'AS-210a', 'AS-210' ] #one plate splills over 2 files, rename later\n",
    "\n",
    "plate_key = dict(zip(files, plates))\n",
    "\n",
    "channel_key = {'YG582/15-A': 'CD34-PE', \n",
    "               'YG670/30-A': 'Lin-PE-Cy5', \n",
    "               'YG780/60-A': 'CD123-PE-Cy7', \n",
    "               'V450/50-A': 'CD90-BV421', \n",
    "               'V610/20-A': 'Zombie', \n",
    "               'B530/30-A': 'CD45RA-FITC', \n",
    "               'R660/20-A': 'IL1RAP-APC', \n",
    "               'R780/60-A': 'CD38-APC-cy7'\n",
    "}\n",
    "\n",
    "logs = ['Lin-PE-Cy5', 'CD34-PE','CD38-APC-cy7', 'CD45RA-FITC','CD123-PE-Cy7','Zombie', 'IL1RAP-APC', 'CD90-BV421' ]\n",
    "\n",
    "plot_list = [\n",
    "    ['FSC-A', 'SSC-A'],\n",
    "    ['FSC-A', 'FSC-W'],\n",
    "    ['SSC-A', 'SSC-H'],\n",
    "    ['Zombie', 'Lin-PE-Cy5'], \n",
    "    ['CD34-PE', 'CD38-APC-cy7'],\n",
    "    ['IL1RAP-APC', 'CD38-APC-cy7'],\n",
    "    ['CD45RA-FITC', 'CD123-PE-Cy7'],\n",
    "    ['CD45RA-FITC', 'CD90-BV421']\n",
    "]\n",
    "#Tweak for EL\n",
    "gates = {\n",
    "    'Lin-PE-Cy5': 900,\n",
    "    'CD34-PE': 4100 ,\n",
    "    'CD38-APC-cy7': 2200 ,  #2200 = 10% on Flowjo, 2900 = 15% , sort looks ~1000\n",
    "    'CD45RA-FITC': 800 ,\n",
    "    'CD123-PE-Cy7': 100,\n",
    "    'Zombie': 1000,\n",
    "    'IL1RAP-APC': 900,  #set from FlowJo looking at unstained, not convinced this worked\n",
    "    'CD90-BV421': 1500\n",
    "}\n",
    "\n",
    "label = 'GR_CD34'\n",
    "plate_qc(directory, label)\n",
    "#source = get_comp_data(directory, plate_key, channel_key, plot = True)\n",
    "#Need to rename placeholder plate AS-210a, and reassign Plate_Well column\n",
    "#source['Plate'] = source['Plate'].replace({'AS-210a':'AS-210'})\n",
    "#source['Plate_Well'] = source['Plate'].astype(str) + '_' + source['Well'].astype(str)\n",
    "#flowplot_byplate(source, plot_list, logs, gates, label)\n",
    "#CD34assigned = MDS_BM_celltype_assign(source, gates, label, save = False)\n",
    "#flowplot_bycelltype(CD34assigned, plot_list, logs, gates,  label, plot = True, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
